# Project: AI-Powered Research Assistant (RAG) ðŸ“„
## Project Description
- The AI-Powered Research Assistant leverages Retrieval-Augmented Generation (RAG) to provide intelligent responses based on research papers. It integrates Groqâ€™s LLM, OpenAI/Hugging Face embeddings, FAISS vector storage, and ChromaDB to efficiently retrieve and summarize information from uploaded PDFs.

## Main Features
- PDF Document Processing: Loads and splits research papers for efficient retrieval.
- Vector Database: Uses FAISS for semantic search and embeddings.
- Groq LLM Integration: Leverages Gemma2-9B-IT for response generation.
- Efficient Retrieval Chain: Combines document retrieval and answer generation.
- Real-Time Response: Measures query execution time for optimization.

## Libraries Used
- streamlit - Web interface
- langchain - LLM and retrieval chains
- PyPDFDirectoryLoader - PDF loading
- FAISS - Vector storage
- OpenAIEmbeddings & HuggingFaceEmbeddings - Text embeddings
- Chroma - Alternative vector DB
- dotenv - Environment variable management

## Objective
To create an AI-powered assistant that extracts, retrieves, and summarizes key insights from research papers, enabling faster and more efficient academic exploration. 

## Deployment Screenshot : ![image](https://github.com/user-attachments/assets/93a853e5-2555-4512-8700-dbab6dab92af)

## Deployment Screenshot : ![image](https://github.com/user-attachments/assets/03f077e4-1a71-474a-9722-0b3698cb7cf6)


